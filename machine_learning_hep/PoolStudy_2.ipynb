{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pickle\n",
    "\n",
    "with open(\"default_complete.yaml\", 'r') as run_config: \n",
    "    data_config = yaml.load(run_config) \n",
    "with open(\"data/database_ml_parameters.yml\", 'r') as param_config: \n",
    "    data_param = yaml.load(param_config) \n",
    "with open(\"data/config_model_parameters.yml\", 'r') as mod_config: \n",
    "    data_model = yaml.load(mod_config) \n",
    "mcordata = \"data\"\n",
    "indexp = 0\n",
    "case = data_config[\"case\"]\n",
    "param_case = data_param[case]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataroot\n",
      "datapkl\n",
      "filesout\n"
     ]
    }
   ],
   "source": [
    "from machine_learning_hep.listfiles import list_files_dir_lev2, list_files_lev2 \n",
    "import multiprocessing as mp\n",
    "import uproot\n",
    "\n",
    "class Processer:\n",
    "    # Class Attribute\n",
    "    species = 'processer'\n",
    "\n",
    "    # Initializer / Instance Attributes\n",
    "    def __init__(self, datap, mcordata, indexp):\n",
    "\n",
    "        self.n_root = datap[\"files_names\"][\"namefile_unmerged_tree\"]\n",
    "        self.n_reco = datap[\"files_names\"][\"namefile_reco\"]\n",
    "        self.n_recosk = datap[\"files_names\"][\"namefile_reco_skim\"]\n",
    "        self.n_treereco = datap[\"files_names\"][\"treeoriginreco\"]\n",
    "        \n",
    "        self.v_all = datap[\"variables\"][\"var_all\"]\n",
    "        \n",
    "        self.s_reco_unp = datap[\"skimming_sel\"]\n",
    "        self.s_reco_skim = datap[\"skimming2_sel\"]\n",
    "        \n",
    "        self.d_root = datap[\"inputs\"][mcordata][\"unmerged_tree_dir\"][indexp]\n",
    "        self.d_reco = datap[\"output_folders\"][\"pkl_out\"][mcordata][indexp]\n",
    "        self.d_recosk = datap[\"output_folders\"][\"pkl_skimmed\"][mcordata][indexp]\n",
    "        \n",
    "        self.l_root = None\n",
    "        self.l_reco = None\n",
    "        self.l_recosk = None\n",
    "        self.maxperchunk = 30\n",
    "        self.indexsample = None\n",
    "        \n",
    "    def set_maxperchunk(self, maxperchunk):\n",
    "        self.maxperchunk = maxperchunk\n",
    "    \n",
    "    def buildlistreco(self):\n",
    "        self.l_root, self.l_reco = list_files_dir_lev2(self.d_root, self.d_reco, self.n_root, self.n_reco)\n",
    "\n",
    "    def buildlistskim(self):\n",
    "        _, self.l_recosk = list_files_dir_lev2(self.d_reco, self.d_recosk, self.n_reco, self.n_recosk)\n",
    "\n",
    "    def unpack(self, file_index):\n",
    "        tree = uproot.open(self.l_root[file_index])[self.n_treereco]\n",
    "        df = tree.pandas.df(branches=self.v_all)\n",
    "        df = df.query(self.s_reco_unp)\n",
    "        df.to_pickle(self.l_reco[file_index])\n",
    "\n",
    "#     def skim(self, filein, fileout):\n",
    "#         df = pickle.load(open(filein, \"rb\"))\n",
    "#         df = df.query(self.s_reco_skim)\n",
    "#         df.to_pickle(fileout)\n",
    "    \n",
    "    def parallelizer(self, function, argument_list):\n",
    "        chunks = [argument_list[x:x+self.maxperchunk] for x in range(0, len(argument_list), self.maxperchunk)]\n",
    "        for chunk in chunks:\n",
    "            pool = mp.Pool(self.maxperchunk)\n",
    "            _ = [pool.apply(function,args=chunk[i]) for i in range(len(chunk))] \n",
    "            pool.close()\n",
    "\n",
    "    def unpacker(self):\n",
    "        self.buildlistreco()\n",
    "        arguments = [(i,) for i in range(len(self.l_root))]\n",
    "        self.parallelizer(self.unpack, arguments)\n",
    "\n",
    "#     def skimmer(self):\n",
    "#         arguments = [(self.l_pkl[i], self.l_pklsk[i]) for i in range(len(self.l_pklsk))]\n",
    "#         self.parallelizer(self.skim, arguments)\n",
    "\n",
    "        \n",
    "myprocess = Processer(data_param[case], mcordata, indexp)\n",
    "myprocess.unpacker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
